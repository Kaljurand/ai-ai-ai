# Speech Playground Specification

## Overview

This tool compares the speech generation and transcription quality of various AI providers. While it still focuses on Estonian examples, the app is meant for experimenting with a wider set of speech services.

## Functional Requirements

### 1. Text Generation

* User can select which models (e.g. Gemini, ChatGPT, Claude, etc.) generate the initial Estonian text.
* Multiple texts can be generated per provider.
* Generated texts should be challenging for TTS and ASR systems:

  * Include numbers and abbreviations (e.g. "nr", "lk") without explicit case endings, e.g. weather forecast
  * Words with unclear palatalization (e.g. "palk") and quantity ("kooli")

### 2. Text-to-Speech (TTS) Conversion

* For each generated text, user can select one or more TTS providers/models.
* Support multiple voice configurations:

  * Different voices
  * Prosody variants (intonation, emphasis)
  * Background noise levels (optional)
* Each combination of input text and TTS model results in a separate audio file.

### 3. Speech-to-Text (ASR) Conversion

* For each generated audio file, user can select one or more ASR/transcription models.
* Each transcription is stored separately and associated with its audio input.

### 4. Comparison & Evaluation

* Calculate the Word Error Rate (WER) for each transcription compared to its original generated text.
* Store all intermediate steps: texts, audio files, transcriptions.
* Generate a comprehensive table listing:

  * Text source (model name, index)
  * TTS provider and configuration
  * ASR provider
  * Link to original text
  * Link to generated audio
  * Link to transcription
  * WER score
  * Token usage per step (text generation, TTS, ASR)
  * Total token usage and cost for the complete task

Example: If 2 texts are generated by Gemini and 1 by ChatGPT, and each is synthesized with Gemini TTS and ChatGPT TTS, you get 6 audio files. If each is then transcribed by Gemini ASR and ChatGPT ASR, you get 12 transcriptions. The final comparison table will contain 12 rows with full traceability, evaluation, token usage, and cost.

### 5. Cost Management

* API usage should be tracked per session.
* Aim to keep total cost under 1 Euro/session (or notify user when estimated cost exceeds this).

## Website Requirements

* Implemented as a single static HTML page.
* Users can paste or upload their own text or audio to skip some of the generation steps.
* A mock mode should be available to simulate outputs when no API key is provided, allowing users to explore the interface and functionality without API access.
* Built using React or a similar frontend framework.
* All inputs and API keys are stored in browser local storage (no backend).
* Allow users to:

  * Select models and configurations for each task. Default to the cheapest models, but inlcude also the latest "pro" models.
  * View a table with all combinations and WERs.
  * Play audio files and view transcripts.
  * Manage audio generation on a dedicated page with options to upload, record or synthesize using selected TTS models.
  * Audio files are listed in a sortable table showing ISO timestamps and provider names, with a delete option for each row.
  * Tabs are fixed to the top of the page. The tabs are:
    * **Text** – generate or upload texts. Example prompts can be inserted here.
    * **Audio** – convert a selected text to audio or upload/record audio. Example prompts help with TTS instructions.
    * **ASR** – transcribe an audio file and view WER/diff results. Example prompts are available for ASR too.
    * **Log** – REST query log.
    * **Models** – view models from OpenRouter, OpenAI and Google.
      The table lists each model's ID, provider, description, modality and
      pricing. Pricing for OpenRouter models is calculated by adding together the
      `prompt` and `completion` cost values. Models can be selected for Text,
      Audio and ASR tasks via checkboxes in this table. A toggle shows only the
      currently selected models.
    * **Settings** – API keys and language selection.
  * A "Log" tab shows all REST queries executed during app usage with timestamps and estimated costs. Ongoing requests appear with spinners until completion and the table includes a hidden duration column.
  * The Text, Audio and ASR tables also allocate placeholder rows for in‑flight operations, displaying spinners until the results arrive.
  * Visualize the transcription errors similar to git diff.
  * Filter, sort, and highlight best-performing combinations. Results tables are sortable and rows can be removed.
  * Clicking any table row (except the action buttons) opens a draggable pop-up showing all cell values. The top bar lists the row ID, timestamp and model IDs. Audio rows and ASR results show a player widget. Markdown, JSON and diff HTML render correctly. Each field has a copy icon and the row action buttons are shown, with a close icon in the corner.
  * Truncated values can be fully viewed in a pop-up preview dialog.
  * Enter optional prompts for text generation, TTS and ASR. These prompts are passed to the providers.
  * Configure API keys in a dedicated configuration tab; model selection is handled on the Models page while prompts remain on their respective pages.
  * Model lists are fetched from provider APIs and displayed in the Models table with pricing where available. Generated prompts are inserted into the TTS prompt field and API errors are shown as toast messages.

## Technologies

* No backend server; all logic implemented in the frontend
* Frontend: React + Charting (e.g. Recharts or Chart.js)
* Storage: Local or cloud storage for generated assets (texts, audio, transcriptions)
* API: Integrate with OpenAI, Google, Anthropic, Meta, etc. Most requests are routed via OpenRouter when possible.
* Fetch model lists and pricing from OpenRouter without requiring an API key.
* All current enhancements (diff view, waveform, prompt editing) are part of the base specification

## Additional Features

* Allow manual editing of generated texts before the TTS step.
* Export the comparison results (texts, audio links, transcripts, WER) as JSON, YAML or Markdown.
* Provide a "Clear Data" option in the Settings tab to wipe all table data while keeping API keys.
* Another "Clear Keys" option removes the stored keys as well.
* A "Reset UI state" button clears prompts, table sort/filter settings, theme and the currently selected tab without removing API keys or chosen models.
* Allow publishing individual ASR result rows to a Google Sheet via the Settings tab.
  * Users must sign in with Google using an OAuth client ID to authorize publishing.
* Display progress indicators and descriptive error messages during each API request, including when API keys are invalid.
* Optional dark mode can be toggled from the Settings tab.
